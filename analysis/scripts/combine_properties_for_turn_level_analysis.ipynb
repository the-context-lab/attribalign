{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# hacky way to import functions from analysis/compute_properties/helpers.py\n",
    "sys.path.insert(1, '../compute_properties/')\n",
    "from helpers import unpipe, pipe, rm_non_alphanum_from_str\n",
    "\n",
    "# ignore warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert sample-level to turn-level dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the list of columns the generated turn-level dataframe will have.\n",
    "\n",
    "| Column | Description | Type |\n",
    "| ------ | ----------- | ---- |\n",
    "| **MAIN DATA** |||\n",
    "| dia_id | ID of original corpus dialogue. | int |\n",
    "| sample_id | Sample index. | int |\n",
    "| gen_id | Model response index. | int |\n",
    "| curr_turn_idx_in_orig | Response utterance index in original dialogue. | int |\n",
    "| dist_from_prev_turn | Distance (of response) from previous utterance in context. | int |\n",
    "| prev_turn_txt | Text of previous utterance. | str |\n",
    "| curr_turn_txt | Text of current (response) utterance. | str |\n",
    "| **LABELS** |||\n",
    "| speaker_curr | Speaker label of current turn. | str |\n",
    "| speaker_prev | Speaker label of previous turn. | str |\n",
    "| is_same_speaker | Whether current and previous utterances were produced by the same speaker. | bool |\n",
    "| **OVERLAPS** | | |\n",
    "| vocab_overlap | VO. | float |\n",
    "| constr_overlap | CO. | float |\n",
    "| constr_overlap_h | CO with human response. | float |\n",
    "| vocab_overlap_h | VO with human response. | float |\n",
    "| abs_diff_m_h_co | Absolute difference of model and human CO. | float |\n",
    "| abs_diff_m_h_vo | Absolute difference of model and human VO. | float |\n",
    "| **ATTRIBUTIONS** |||\n",
    "| attrib_to_prev | Attribution to previous utterance. | float |\n",
    "| attrib_to_curr | Attribution to current utterance (response). | float |\n",
    "| attrib_to_curr_comp | Attribution to current utterance while comprehending human response. | float |\n",
    "| attrib_to_prev_comp | Attribution to previous utterance while comprehending human response. | float |\n",
    "| mean_attrib | Mean attribution to utterances in the context. | float |\n",
    "| mean_attrib_comp | Mean attribution to utterances in the context (while comprehending). | float |\n",
    "| s_attrib_to_curr | Attribution to current utt. speaker label. | float |\n",
    "| s_attrib_to_curr_comp | Comprehension attribution to current utt. speaker label. | float |\n",
    "| s_attrib_to_prev | Attrib. to previous utt. speaker label. | float |\n",
    "| s_attrib_to_prev_comp | Comprehension attrib. to previous utt. speaker label. | float |\n",
    "| s_mean_attrib | Mean attribution to speaker labels in the context. | float |\n",
    "| s_mean_attrib_comp | Mean attribution to speaker labels in the context (while comprehending). | float |\n",
    "| **CONSTRUCTIONS** |||\n",
    "| constrs | List of constructions. | pipe-separated strs |\n",
    "| constr_lens | Lengths of constructions (in words). | pipe-separated ints |\n",
    "| constr_freqs | Occurence frequencies of constructions. | pipe-separated ints |\n",
    "| avg_constr_len | Mean construction length (in words). | float |\n",
    "| pmi | PMI of constructions. | pipe-separated floats |\n",
    "| pmi_avg | Mean PMI. | float |\n",
    "| repeated_words | List of repeated words between the two utterances. | pipe-separated strs |\n",
    "| non_rep_constrs | List of non-repeated constructions. | |\n",
    "| n_words_not_in_ctx | Number of words in the response that are not in the context. | |\n",
    "| **GENERATION QUALITY** |||\n",
    "| bert_precision | BERTScore precision. | float |\n",
    "| bert_recall | BERTScore recall. | float |\n",
    "| bert_f1 | BERTScore F1. | float |\n",
    "| bleu | BLEU score. | float |\n",
    "| bleu_brevity_penalty | BLEU brevity penalty. | float |\n",
    "| bleu_length_ratio | BLEU length ratio. | float |\n",
    "| bleu_translation_length | BLEU translation length. | float |\n",
    "| bleu_reference_length | BLEU reference length. | float |\n",
    "| **PERPLEXITIES** |||\n",
    "| ppl_gpt2_model_trg_dectx | PPL (perplexity) of GPT-2 on current utterance (without context). | float |\n",
    "| ppl_gpt2_human_trg_dectx | PPL of GPT-2 on the human-produced response (without context). | float |\n",
    "| abs_diff_ppl_gpt2_dectx | Absolute difference between the above two columns. | float |\n",
    "| ppl_gpt2_model_trg_ctx | PPL of GPT-2 on current utterance (with context). | float |\n",
    "| ppl_gpt2_human_trg_ctx | PPL of GPT-2 on human response (with context). | float |\n",
    "| abs_diff_ppl_gpt2_ctx | Absolute difference between the above two columns. | float |\n",
    "| ppl_pythia_model_trg_dectx | See above. Model is Pythia-1.4b instead of GPT-2 | float |\n",
    "| ppl_pythia_human_trg_dectx | ^ | float |\n",
    "| abs_diff_ppl_pythia_dectx | ^ | float |\n",
    "| ppl_pythia_model_trg_ctx | ^ | float |\n",
    "| ppl_pythia_human_trg_ctx | ^ | float |\n",
    "| abs_diff_ppl_pythia_ctx | ^ | float |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sample_2_turn_level(\n",
    "        sample_level_file: str,\n",
    "        turn_level_file: str = None,\n",
    "        n_model_responses: int = 5,\n",
    "        save_every: int = 50,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a sample-level dataframe to a turn-level dataframe.\n",
    "\n",
    "    :param sample_level_file: str\n",
    "        Path to the sample-level dataframe (input).\n",
    "    :param turn_level_file: str\n",
    "        Path to the turn-level dataframe (output).\n",
    "        If not specified, the created dataframe will be returned.\n",
    "    :return: pd.DataFrame\n",
    "        Turn-level dataframe.\n",
    "    \"\"\"\n",
    "    samples = pd.read_csv(\n",
    "        sample_level_file,\n",
    "        sep='\\t',\n",
    "        header=0,\n",
    "        index_col='sample_index',\n",
    "    )\n",
    "\n",
    "    ppl_models = set([\n",
    "        col.split('_')[-1].strip().lower()\n",
    "        for col in samples.columns\n",
    "        if col.startswith('ppl_')\n",
    "    ])\n",
    "\n",
    "    turn_cols = [\n",
    "        # ---------------------\n",
    "        # MAIN COLS\n",
    "        # ---------------------\n",
    "        # 'dia_id',\n",
    "        'sample_id',\n",
    "        'gen_id',\n",
    "        'curr_turn_idx_in_orig',\n",
    "        'dist_from_prev_turn',\n",
    "        'prev_turn_txt',\n",
    "        'curr_turn_txt',\n",
    "        'human_resp_txt',  # NEW\n",
    "        # ---------------------\n",
    "        # LABELS\n",
    "        # ---------------------\n",
    "        'speaker_curr',\n",
    "        'speaker_prev',\n",
    "        'is_same_speaker',\n",
    "        # ---------------------\n",
    "        # OVERLAPS\n",
    "        # ---------------------\n",
    "        'vocab_overlap',\n",
    "        'constr_overlap',\n",
    "        'constr_overlap_h',  # CO with human response\n",
    "        'vocab_overlap_h'  # VO with human response\n",
    "        'abs_diff_m_h_co',  # |CO - CO_h|\n",
    "        'abs_diff_m_h_vo',  # |VO - VO_h|\n",
    "        # ---------------------\n",
    "        # ATTRIBUTIONS\n",
    "        # ---------------------\n",
    "        'attrib_to_prev',\n",
    "        'attrib_to_curr',\n",
    "        'attrib_to_curr_comp',  # attrib_to_curr while comprehending human response\n",
    "        'attrib_to_prev_comp',\n",
    "        'mean_attrib',\n",
    "        'mean_attrib_comp',\n",
    "        's_attrib_to_curr'  # attrib to [s]peaker label\n",
    "        's_attrib_to_curr_comp',\n",
    "        's_attrib_to_prev',\n",
    "        's_attrib_to_prev_comp',\n",
    "        's_mean_attrib',\n",
    "        's_mean_attrib_comp',\n",
    "        # ---------------------\n",
    "        # CONSTRUCTIONS\n",
    "        # ---------------------\n",
    "        'constrs',\n",
    "        'constr_lens',\n",
    "        'constr_freqs',\n",
    "        'avg_constr_len',\n",
    "        'pmi',\n",
    "        'pmi_avg',\n",
    "        'repeated_words',\n",
    "        # 'non_rep_constrs',  # ???\n",
    "        'n_words_not_in_ctx',\n",
    "        # ---------------------\n",
    "        # GENERATION QUALITY\n",
    "        # ---------------------\n",
    "        # 'bert_precision',\n",
    "        # 'bert_recall',\n",
    "        'bert_f1',\n",
    "        'bleu',\n",
    "        'bleu_brevity_penalty',\n",
    "        'bleu_length_ratio',\n",
    "        # 'bleu_translation_length',\n",
    "        # 'bleu_reference_length',\n",
    "        'mauve',  # NEW, corpus-level\n",
    "    ]\n",
    "    # ---------------------\n",
    "    # PERPLEXITIES\n",
    "    # ---------------------\n",
    "    if 'gpt2' in ppl_models:\n",
    "        turn_cols += [\n",
    "            # GPT-2:\n",
    "            'ppl_gpt2_model_trg_dectx',\n",
    "            'ppl_gpt2_human_trg_dectx',\n",
    "            'abs_diff_ppl_gpt2_dectx',  # |ppl_gpt2_model_trg_dectx - ppl_gpt2_human_trg_dectx|\n",
    "            'ppl_gpt2_model_trg_ctx',\n",
    "            'ppl_gpt2_human_trg_ctx',\n",
    "            'abs_diff_ppl_gpt2_ctx',  # |ppl_gpt2_model_trg_ctx - ppl_gpt2_human_trg_ctx|\n",
    "        ]\n",
    "    if 'pythia' in ppl_models:\n",
    "        turn_cols += [\n",
    "            # Pythia-1.4b:\n",
    "            'ppl_pythia_model_trg_dectx',\n",
    "            'ppl_pythia_human_trg_dectx',\n",
    "            'abs_diff_ppl_pythia_dectx',  # |ppl_pythia_model_trg_dectx - ppl_pythia_human_trg_dectx|\n",
    "            'ppl_pythia_model_trg_ctx',\n",
    "            'ppl_pythia_human_trg_ctx',\n",
    "            'abs_diff_ppl_pythia_ctx',  # |ppl_pythia_model_trg_ctx - ppl_pythia_human_trg_ctx|\n",
    "        ]\n",
    "    turns = pd.DataFrame(columns=turn_cols)\n",
    "\n",
    "    def save_turn_level_to_disk():\n",
    "        turns.to_csv(\n",
    "            turn_level_file, \n",
    "            sep='\\t', \n",
    "            header=True, \n",
    "            index=True,\n",
    "            index_label='index',\n",
    "        )\n",
    "\n",
    "    \"\"\"\n",
    "    - Each row in the sample-level dataframe will correspond to\n",
    "      n_utts_context * n_model_responses rows in the turn-level dataframe.\n",
    "      That is 9 * 5 = 45 rows if the context length is 10 and the number of\n",
    "      model responses is 5.\n",
    "    - We pair each response with all the utterance of the context.\n",
    "    \"\"\"\n",
    "    for sample_index, sample in tqdm(\n",
    "        samples.iterrows(), \n",
    "        total=len(samples)\n",
    "    ):\n",
    "        # prep excerpt utterances\n",
    "        context = sample['prompt'].strip()\n",
    "        context = [utt.strip() for utt in context.split('\\\\n')]\n",
    "        context = [{'label': utt[:1].strip(), 'utt': utt[2:].strip()} for utt in context]\n",
    "        n_utts_ctx = len(context)\n",
    "        # prep human response\n",
    "        human_response = sample['human_response'].strip()\n",
    "        human_response = {'label': human_response[:1].strip(), 'utt': human_response[2:].strip()}\n",
    "        response_label = human_response['label']\n",
    "        # prep model responses\n",
    "        model_responses = []\n",
    "        for gen_idx in range(n_model_responses):\n",
    "            try:\n",
    "                model_resp = sample[f'model_response_r{gen_idx}'].replace('\\\\n', '').strip()\n",
    "            except AttributeError:\n",
    "                # empty model response\n",
    "                model_resp = ''\n",
    "            model_responses.append({\n",
    "                'label': response_label,\n",
    "                'utt': model_resp\n",
    "            })\n",
    "        # get words set in context\n",
    "        words_ctx = [\n",
    "            rm_non_alphanum_from_str(utt['utt'].strip().lower()).strip().split()\n",
    "            for utt in context\n",
    "        ]\n",
    "        words_ctx = [word for utt in words_ctx for word in utt]  # flatten\n",
    "        words_ctx = set(words_ctx)\n",
    "\n",
    "        # get overlap scores and quality scores\n",
    "        vos_human = unpipe(sample['vo_human'])\n",
    "        cos_human = unpipe(sample['co_human'])\n",
    "        mauve_score = sample['mauve_score']\n",
    "        bleu_score = sample['bleu_score']\n",
    "        bleu_bp = sample['bleu_brevity_penalty']\n",
    "        bleu_lr = sample['bleu_length_ratio']\n",
    "        # get comprehension attribution scores\n",
    "        attribs_comp = unpipe(sample['comprehend_attribs'])[::-1]\n",
    "        attribs_tag_comp = unpipe(sample['comprehend_attribs_tag'])[::-1]\n",
    "        attrib_curr_comp = attribs_comp[-1] if len(attribs_comp) > 0 else np.nan\n",
    "        attrib_curr_tag_comp = attribs_tag_comp[-1] if len(attribs_tag_comp) > 0 else np.nan\n",
    "        attribs_comp = attribs_comp[:-1]  # remove response\n",
    "        attribs_tag_comp = attribs_tag_comp[:-1]  # remove response\n",
    "        mean_attrib_comp = np.nanmean(attribs_comp)\n",
    "        mean_attrib_tag_comp = np.nanmean(attribs_tag_comp)\n",
    "\n",
    "        # iterate over model responses\n",
    "        for gen_idx, model_response in enumerate(model_responses):\n",
    "\n",
    "            # get current utterance and scores\n",
    "            curr_utt = model_response['utt']\n",
    "            vos = unpipe(sample[f\"vo_r{gen_idx}\"])\n",
    "            cos = unpipe(sample[f\"co_r{gen_idx}\"])\n",
    "            bert_f1 = sample[f\"bert_f1_r{gen_idx}\"]\n",
    "            # get attribution scores.\n",
    "            # reverse attribution scores list\n",
    "            # the original list contains scores where the first element\n",
    "            # is the score for the response and the last element is the\n",
    "            # score for the first utterance in the context\n",
    "            attribs = unpipe(sample[f\"attribs_r{gen_idx}\"])[::-1]\n",
    "            attribs_tag = unpipe(sample[f\"attribs_tag_r{gen_idx}\"])[::-1]\n",
    "            attrib_curr = attribs[-1] if len(attribs) > 0 else np.nan\n",
    "            attrib_curr_tag = attribs_tag[-1] if len(attribs_tag) > 0 else np.nan\n",
    "            attribs = attribs[:-1]  # remove response\n",
    "            attribs_tag = attribs_tag[:-1]  # remove response\n",
    "            mean_attrib = np.nanmean(attribs)\n",
    "            mean_attrib_tag = np.nanmean(attribs_tag)\n",
    "            # get pmi\n",
    "            pmi = sample[f\"pmi_r{gen_idx}\"]\n",
    "            pmi_avg = np.nanmean(unpipe(pmi))\n",
    "            \n",
    "            # iterate over context utterances\n",
    "            for turn_idx, turn in enumerate(context):\n",
    "\n",
    "                # get previous utterance and repeated words\n",
    "                prev_utt = turn['utt']\n",
    "                repeated_words = pipe(\n",
    "                    set(curr_utt.strip().split()) \\\n",
    "                        .intersection(set(prev_utt.split()))\n",
    "                )\n",
    "                # get constructions\n",
    "                constrs = unpipe(sample[f\"constrs_model_r{gen_idx}_turn{turn_idx}\"])\n",
    "                constr_lens = ''\n",
    "                if len(constrs) > 0:\n",
    "                    constr_lens = [\n",
    "                        len(constr.strip().split())\n",
    "                        for constr in constrs\n",
    "                    ]\n",
    "                    constr_lens = pipe(constr_lens)\n",
    "                constr_freqs = sample[f\"constr_freqs_model_r{gen_idx}_turn{turn_idx}\"]\n",
    "                avg_constr_len = np.nanmean(constr_lens) if not isinstance(constr_lens, str) else np.nan\n",
    "\n",
    "                # determine number of words not in context\n",
    "                words_curr = set(rm_non_alphanum_from_str(curr_utt.strip().lower()).strip().split())\n",
    "                word_not_in_ctx = words_curr - words_ctx\n",
    "                n_words_not_in_ctx = len(word_not_in_ctx)\n",
    "                \n",
    "                # create new row in the turn-level dataframe\n",
    "                new_row = dict(\n",
    "                    # main cols:\n",
    "                    sample_id=sample_index,\n",
    "                    gen_id=gen_idx,\n",
    "                    curr_turn_idx_in_orig=sample['first_utt_idx_in_diag'] + n_utts_ctx,\n",
    "                    dist_from_prev_turn=n_utts_ctx - turn_idx + 1,  # 0: same, 10: first utt in ctx\n",
    "                    prev_turn_txt=prev_utt,\n",
    "                    curr_turn_txt=curr_utt,\n",
    "                    human_resp_txt=human_response['utt'],\n",
    "                    # labels:\n",
    "                    speaker_curr=model_response['label'],\n",
    "                    speaker_prev=turn['label'],\n",
    "                    is_same_speaker=int(model_response['label'] == turn['label']),\n",
    "                    # overlaps:\n",
    "                    vocab_overlap=vos[turn_idx] if len(vos) > 0 else np.nan,\n",
    "                    constr_overlap=cos[turn_idx] if len(cos) > 0 else np.nan,\n",
    "                    constr_overlap_h=cos_human[turn_idx] if len(cos_human) > 0 else np.nan,\n",
    "                    vocab_overlap_h=vos_human[turn_idx] if len(vos_human) > 0 else np.nan,\n",
    "                    abs_diff_m_h_co=np.abs(cos[turn_idx] - cos_human[turn_idx]) if len(cos) > 0 else np.nan,\n",
    "                    abs_diff_m_h_vo=np.abs(vos[turn_idx] - vos_human[turn_idx]) if len(vos) > 0 else np.nan,\n",
    "                    # attributions:\n",
    "                    attrib_to_prev=attribs[turn_idx] if len(attribs) > 0 else np.nan,\n",
    "                    attrib_to_curr=attrib_curr,\n",
    "                    attrib_to_curr_comp=attrib_curr_comp,\n",
    "                    attrib_to_prev_comp=attribs_comp[turn_idx] if len(attribs_comp) > 0 else np.nan,\n",
    "                    mean_attrib=mean_attrib,\n",
    "                    mean_attrib_comp=mean_attrib_comp,\n",
    "                    s_attrib_to_curr=attrib_curr_tag,\n",
    "                    s_attrib_to_curr_comp=attrib_curr_tag_comp,\n",
    "                    s_attrib_to_prev=attribs_tag[turn_idx] if len(attribs_tag) > 0 else np.nan,\n",
    "                    s_attrib_to_prev_comp=attribs_tag_comp[turn_idx] if len(attribs_tag_comp) > 0 else np.nan,\n",
    "                    s_mean_attrib=mean_attrib_tag,\n",
    "                    s_mean_attrib_comp=mean_attrib_tag_comp,\n",
    "                    # constructions:\n",
    "                    constrs=constrs,\n",
    "                    constr_lens=constr_lens,\n",
    "                    constr_freqs=constr_freqs,\n",
    "                    avg_constr_len=avg_constr_len,\n",
    "                    pmi=pmi,\n",
    "                    pmi_avg=pmi_avg,\n",
    "                    repeated_words=repeated_words,\n",
    "                    # non_rep_constrs=None,\n",
    "                    n_words_not_in_ctx=n_words_not_in_ctx,\n",
    "                    # gen quality:\n",
    "                    # bert_precision=None,\n",
    "                    # bert_recall=None,\n",
    "                    bert_f1=bert_f1,\n",
    "                    bleu=bleu_score,\n",
    "                    bleu_brevity_penalty=bleu_bp,\n",
    "                    bleu_length_ratio=bleu_lr,\n",
    "                    # bleu_translation_length=None,\n",
    "                    # bleu_reference_length=None,\n",
    "                    mauve=mauve_score,  # TODO: currently this is corpus-level, break into corpus/generation/model/model_type\n",
    "                )\n",
    "                # perplexities:\n",
    "                if 'gpt2' in ppl_models:\n",
    "                    new_row.update(dict(\n",
    "                        # GPT-2:\n",
    "                        ppl_gpt2_model_trg_dectx=sample[f\"ppl_model_response_r{gen_idx}_gpt2\"],\n",
    "                        ppl_gpt2_human_trg_dectx=sample[f\"ppl_human_response_gpt2\"],\n",
    "                        abs_diff_ppl_gpt2_dectx=np.abs(\n",
    "                            sample[f\"ppl_model_response_r{gen_idx}_gpt2\"] - \n",
    "                            sample[f\"ppl_human_response_gpt2\"]\n",
    "                        ),\n",
    "                        ppl_gpt2_model_trg_ctx=sample[f\"ppl_model_response_r{gen_idx}_context_gpt2\"],\n",
    "                        ppl_gpt2_human_trg_ctx=sample[f\"ppl_human_response_context_gpt2\"],\n",
    "                        abs_diff_ppl_gpt2_ctx=np.abs(\n",
    "                            sample[f\"ppl_model_response_r{gen_idx}_context_gpt2\"] - \n",
    "                            sample[f\"ppl_human_response_context_gpt2\"]\n",
    "                        ),\n",
    "                    ))\n",
    "                if 'pythia' in ppl_models:\n",
    "                    new_row.update(dict(\n",
    "                        # Pythia-1.4b:\n",
    "                        ppl_pythia_model_trg_dectx=sample[f\"ppl_model_response_r{gen_idx}_pythia\"],\n",
    "                        ppl_pythia_human_trg_dectx=sample[f\"ppl_human_response_pythia\"],\n",
    "                        abs_diff_ppl_pythia_dectx=np.abs(\n",
    "                            sample[f\"ppl_model_response_r{gen_idx}_pythia\"] - \n",
    "                            sample[f\"ppl_human_response_pythia\"]\n",
    "                        ),\n",
    "                        ppl_pythia_model_trg_ctx=sample[f\"ppl_model_response_r{gen_idx}_context_pythia\"],\n",
    "                        ppl_pythia_human_trg_ctx=sample[f\"ppl_human_response_context_pythia\"],\n",
    "                        abs_diff_ppl_pythia_ctx=np.abs(\n",
    "                            sample[f\"ppl_model_response_r{gen_idx}_context_pythia\"] - \n",
    "                            sample[f\"ppl_human_response_context_pythia\"]\n",
    "                        ),\n",
    "                    ))\n",
    "\n",
    "                # add new row to the turn-level dataframe\n",
    "                turns = pd.concat([turns, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "        if turn_level_file is not None and sample_index % save_every == 0:\n",
    "            save_turn_level_to_disk()\n",
    "\n",
    "    # save turn-level dataframe\n",
    "    if turn_level_file is not None:\n",
    "        save_turn_level_to_disk()\n",
    "    return turns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:01<00:00,  5.26it/s]\n"
     ]
    }
   ],
   "source": [
    "tl = convert_sample_2_turn_level(\n",
    "    sample_level_file = '../../data/samples_mini_gpt2_genq_constr_ppl_ol_pmi.tsv',\n",
    "    turn_level_file   = '../../data/turns_mini_gpt2_genq_constr_ppl_ol_pmi.tsv',\n",
    "    save_every=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>gen_id</th>\n",
       "      <th>curr_turn_idx_in_orig</th>\n",
       "      <th>dist_from_prev_turn</th>\n",
       "      <th>prev_turn_txt</th>\n",
       "      <th>curr_turn_txt</th>\n",
       "      <th>human_resp_txt</th>\n",
       "      <th>speaker_curr</th>\n",
       "      <th>speaker_prev</th>\n",
       "      <th>is_same_speaker</th>\n",
       "      <th>...</th>\n",
       "      <th>ppl_gpt2_model_trg_dectx</th>\n",
       "      <th>ppl_gpt2_human_trg_dectx</th>\n",
       "      <th>abs_diff_ppl_gpt2_dectx</th>\n",
       "      <th>ppl_gpt2_model_trg_ctx</th>\n",
       "      <th>ppl_gpt2_human_trg_ctx</th>\n",
       "      <th>abs_diff_ppl_gpt2_ctx</th>\n",
       "      <th>vocab_overlap_h</th>\n",
       "      <th>abs_diff_m_h_co</th>\n",
       "      <th>s_attrib_to_curr</th>\n",
       "      <th>s_attrib_to_curr_comp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>Oh, for sure.. Oh, yeah.</td>\n",
       "      <td>Uh.. but, you know,. a pet. I mean, I sometime...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.838915</td>\n",
       "      <td>4.977974</td>\n",
       "      <td>1.139059</td>\n",
       "      <td>2.833378</td>\n",
       "      <td>2.862912</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>-0.234607</td>\n",
       "      <td>-0.670036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>So, I've had this dog now for, for sixteen yea...</td>\n",
       "      <td>Uh.. but, you know,. a pet. I mean, I sometime...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.838915</td>\n",
       "      <td>4.977974</td>\n",
       "      <td>1.139059</td>\n",
       "      <td>2.833378</td>\n",
       "      <td>2.862912</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>-0.234607</td>\n",
       "      <td>-0.670036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>Yes,. well. My, my mother has one that's, uh,....</td>\n",
       "      <td>Uh.. but, you know,. a pet. I mean, I sometime...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.838915</td>\n",
       "      <td>4.977974</td>\n",
       "      <td>1.139059</td>\n",
       "      <td>2.833378</td>\n",
       "      <td>2.862912</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>-0.234607</td>\n",
       "      <td>-0.670036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>Uh-huh.</td>\n",
       "      <td>Uh.. but, you know,. a pet. I mean, I sometime...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.838915</td>\n",
       "      <td>4.977974</td>\n",
       "      <td>1.139059</td>\n",
       "      <td>2.833378</td>\n",
       "      <td>2.862912</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.234607</td>\n",
       "      <td>-0.670036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>But, uh, it was, it, it's it's really made suc...</td>\n",
       "      <td>Uh.. but, you know,. a pet. I mean, I sometime...</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.838915</td>\n",
       "      <td>4.977974</td>\n",
       "      <td>1.139059</td>\n",
       "      <td>2.833378</td>\n",
       "      <td>2.862912</td>\n",
       "      <td>0.029535</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>-0.234607</td>\n",
       "      <td>-0.670036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id gen_id curr_turn_idx_in_orig dist_from_prev_turn  \\\n",
       "0       978      0                    32                  10   \n",
       "1       978      0                    32                   9   \n",
       "2       978      0                    32                   8   \n",
       "3       978      0                    32                   7   \n",
       "4       978      0                    32                   6   \n",
       "\n",
       "                                       prev_turn_txt  \\\n",
       "0                           Oh, for sure.. Oh, yeah.   \n",
       "1  So, I've had this dog now for, for sixteen yea...   \n",
       "2  Yes,. well. My, my mother has one that's, uh,....   \n",
       "3                                            Uh-huh.   \n",
       "4  But, uh, it was, it, it's it's really made suc...   \n",
       "\n",
       "                                       curr_turn_txt human_resp_txt  \\\n",
       "0  Uh.. but, you know,. a pet. I mean, I sometime...          Yeah.   \n",
       "1  Uh.. but, you know,. a pet. I mean, I sometime...          Yeah.   \n",
       "2  Uh.. but, you know,. a pet. I mean, I sometime...          Yeah.   \n",
       "3  Uh.. but, you know,. a pet. I mean, I sometime...          Yeah.   \n",
       "4  Uh.. but, you know,. a pet. I mean, I sometime...          Yeah.   \n",
       "\n",
       "  speaker_curr speaker_prev is_same_speaker  ...  ppl_gpt2_model_trg_dectx  \\\n",
       "0            A            B               0  ...                  3.838915   \n",
       "1            A            A               1  ...                  3.838915   \n",
       "2            A            B               0  ...                  3.838915   \n",
       "3            A            A               1  ...                  3.838915   \n",
       "4            A            B               0  ...                  3.838915   \n",
       "\n",
       "   ppl_gpt2_human_trg_dectx  abs_diff_ppl_gpt2_dectx ppl_gpt2_model_trg_ctx  \\\n",
       "0                  4.977974                 1.139059               2.833378   \n",
       "1                  4.977974                 1.139059               2.833378   \n",
       "2                  4.977974                 1.139059               2.833378   \n",
       "3                  4.977974                 1.139059               2.833378   \n",
       "4                  4.977974                 1.139059               2.833378   \n",
       "\n",
       "   ppl_gpt2_human_trg_ctx  abs_diff_ppl_gpt2_ctx  vocab_overlap_h  \\\n",
       "0                2.862912               0.029535              0.5   \n",
       "1                2.862912               0.029535              0.5   \n",
       "2                2.862912               0.029535              0.5   \n",
       "3                2.862912               0.029535              0.5   \n",
       "4                2.862912               0.029535              0.5   \n",
       "\n",
       "   abs_diff_m_h_co  s_attrib_to_curr  s_attrib_to_curr_comp  \n",
       "0         0.434783         -0.234607              -0.670036  \n",
       "1         0.130435         -0.234607              -0.670036  \n",
       "2         0.434783         -0.234607              -0.670036  \n",
       "3         0.000000         -0.234607              -0.670036  \n",
       "4         0.130435         -0.234607              -0.670036  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 49)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
