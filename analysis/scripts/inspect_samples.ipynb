{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect sample-level dataframes\n",
    "\n",
    "We do this as a sanity check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    'human_response': '\\033[92m',\n",
    "    'model_response': '\\033[91m',\n",
    "    'utterance_index': '\\033[93m',\n",
    "    'label_a': '\\033[95m',\n",
    "    'label_b': '\\033[96m',\n",
    "    'end': '\\033[0m'\n",
    "}\n",
    "\n",
    "\n",
    "def break_long_utterance(utterance: str, max_chars: int):\n",
    "    broken_lines = ''\n",
    "    for idx_char, char in enumerate(utterance):\n",
    "        if idx_char % max_chars == 0 and idx_char != 0:\n",
    "            broken_lines += '\\n' + ' ' * 8\n",
    "        broken_lines += char\n",
    "    return broken_lines\n",
    "\n",
    "\n",
    "def pretty_print_prompt(\n",
    "        df_row: pd.Series, \n",
    "        model_name: str = None,\n",
    "        max_chars: int = 80,\n",
    "):\n",
    "    prompt = df_row['prompt']\n",
    "    human_response = df_row['human_response']\n",
    "    prompt = prompt.replace('\\\\n', '\\n').strip()\n",
    "    human_response = human_response.replace('\\\\n', '\\n').strip()\n",
    "\n",
    "    corpus_name = df_row['corpus']\n",
    "    sample_index = df_row.name\n",
    "    print(f\"--- EXCERPT [{sample_index}] FROM [{corpus_name.upper()}] CORPUS ---\")\n",
    "\n",
    "    # break prompt into lines and speaker labels\n",
    "    prompt_lines = prompt.split('\\n')\n",
    "    speaker_labels = []\n",
    "    for line in prompt_lines:\n",
    "        speaker_labels.append(line[:2])\n",
    "    prompt_lines = [line[2:].strip() for line in prompt_lines]\n",
    "\n",
    "    # insert breaks into utterances if they are too long\n",
    "    for i in range(len(prompt_lines)):\n",
    "        prompt_lines[i] = break_long_utterance(prompt_lines[i], max_chars)\n",
    "\n",
    "    # print prompt\n",
    "    for i in range(len(prompt_lines)):\n",
    "        # print utterance index\n",
    "        print(colors['utterance_index'] + f\"[{i+1}]  \" + colors['end'], end='')\n",
    "        # print speaker label\n",
    "        is_a = speaker_labels[i] == 'A:'\n",
    "        color_utterance = colors['label_a' if is_a else 'label_b']\n",
    "        print(color_utterance + speaker_labels[i] + colors['end'] + ' ', end='')\n",
    "        # print utterance\n",
    "        print(color_utterance + prompt_lines[i] + colors['end'])\n",
    "    \n",
    "    # insert breaks into utterances if they are too long\n",
    "    human_response = break_long_utterance(human_response, max_chars)\n",
    "\n",
    "    # print human response\n",
    "    last_utt_string = f\"[{len(prompt_lines) + 1}] \"\n",
    "    print(colors['utterance_index'] + last_utt_string + colors['end'], end='')\n",
    "    print(colors['human_response'] + '[HUMAN]' + colors['end'])\n",
    "    human_label = human_response[:2]\n",
    "    human_response = human_response[2:].strip()\n",
    "    human_color = colors['label_a' if human_label == 'A:' else 'label_b']\n",
    "    spaces_before = ' ' * len(last_utt_string)\n",
    "    print(spaces_before + human_color + human_label + colors['end'] + ' ', end='')\n",
    "    print(human_color + human_response + colors['end'])\n",
    "    \n",
    "    # check if model response columns are not empty\n",
    "    all_cols = df_row.index\n",
    "    model_response_cols = [col for col in all_cols if col.strip().startswith('model_response_r')]\n",
    "    model_responses = []\n",
    "    for col in model_response_cols:\n",
    "        model_response = df_row[col]\n",
    "        if isinstance(model_response, str) and len(model_response) > 0:\n",
    "            model_responses.append(model_responses)\n",
    "    n_model_responses = len(model_responses)\n",
    "    if n_model_responses == 0:\n",
    "        return\n",
    "    \n",
    "    # model sample string\n",
    "    model_string = lambda i: colors['utterance_index'] + last_utt_string + colors['end'] + \\\n",
    "        colors['model_response'] + \\\n",
    "        (f\"[MODEL - SAMPLE {i+1}]\" if model_name is None else f\"[{model_name.upper()} - SAMPLE {i+1}]\") + \\\n",
    "        colors['end']\n",
    "\n",
    "    # print model responses\n",
    "    for i in range(n_model_responses):\n",
    "        col_name = f\"model_response_r{i}\"\n",
    "        model_response = df_row[col_name]\n",
    "        model_response = model_response.replace('\\\\n', ' ').strip()\n",
    "        model_response = human_label + ' ' + model_response\n",
    "        model_response = break_long_utterance(model_response, max_chars)\n",
    "        print(model_string(i))\n",
    "        print(spaces_before + human_color + model_response + colors['end'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 10\n",
      "Columns: 175\n",
      "Index: sample_index\n",
      "\n",
      "COLUMNS:\n",
      "[turns_in_diag]: 88\n",
      "[first_utt_idx_in_diag]: 23\n",
      "[human_response]: A:Yeah.\n",
      "[prompt]: B:Oh, for sure.. Oh, yeah.\\nA:So, I've had this dog now for,...\n",
      "[corpus]: switchboard\n",
      "[model_response_r0]: Uh.. but, you know,. a pet. I mean, I sometimes have, um, pe...\n",
      "[attribs_r0]: -0.8380187153816223|-0.19676153361797333|-0.1018861606717109...\n",
      "[attribs_tag_r0]: -0.23460747301578522|-0.39912521839141846|-0.287821799516677...\n",
      "[model_response_r1]: Ah, now, uh.. I've been thinking about that.\\n\n",
      "[attribs_r1]: 0.10311585664749146|-0.2600320279598236|-0.44083258509635925...\n",
      "[attribs_tag_r1]: -0.6929109692573547|0.0055464101023972034|-0.922957122325897...\n",
      "[model_response_r2]: Uh..\\n\n",
      "[attribs_r2]: 1.0|-0.0011756449239328504|-0.028232935816049576|-0.00375789...\n",
      "[attribs_tag_r2]: -0.46264511346817017|0.19447404146194458|0.2580307722091675|...\n",
      "[model_response_r3]: Right . . . it would lay down on me and that's, it. and, uhâ€¦...\n",
      "[attribs_r3]: 0.06948333233594894|-0.13233807682991028|-0.1277893632650375...\n",
      "[attribs_tag_r3]: -1.0|0.04056968539953232|0.10682133585214615|-0.060485936701...\n",
      "[model_response_r4]: Uh, that cat would. It's kind of, that it would be very, ver...\n",
      "[attribs_r4]: -0.7957656979560852|-0.24644812941551208|-0.3159664869308471...\n",
      "[attribs_tag_r4]: -0.30275022983551025|0.18634876608848572|-0.3068681955337524...\n",
      "[bleu_score]: 0.0\n",
      "[bleu_brevity_penalty]: 1.0\n",
      "[bleu_length_ratio]: 1.1888888888888889\n",
      "[mauve_score]: 0.0040720962619612\n",
      "[bert_f1_r0]: 0.6315169334411621\n",
      "[bert_f1_r1]: 0.6672281622886658\n",
      "[bert_f1_r2]: 0.6616330146789551\n",
      "[bert_f1_r3]: 0.623701274394989\n",
      "[bert_f1_r4]: 0.62032151222229\n",
      "[constrs_human_turn0]: nan\n",
      "[constr_freqs_human_turn0]: nan\n",
      "[constrs_model_r0_turn0]: nan\n",
      "[constr_freqs_model_r0_turn0]: nan\n",
      "[constrs_model_r1_turn0]: nan\n",
      "[constr_freqs_model_r1_turn0]: nan\n",
      "[constrs_model_r2_turn0]: nan\n",
      "[constr_freqs_model_r2_turn0]: nan\n",
      "[constrs_model_r3_turn0]: nan\n",
      "[constr_freqs_model_r3_turn0]: nan\n",
      "[constrs_model_r4_turn0]: nan\n",
      "[constr_freqs_model_r4_turn0]: nan\n",
      "[constrs_human_turn1]: nan\n",
      "[constr_freqs_human_turn1]: nan\n",
      "[constrs_model_r0_turn1]: , you know\n",
      "[constr_freqs_model_r0_turn1]: 4.0\n",
      "[constrs_model_r1_turn1]: nan\n",
      "[constr_freqs_model_r1_turn1]: nan\n",
      "[constrs_model_r2_turn1]: nan\n",
      "[constr_freqs_model_r2_turn1]: nan\n",
      "[constrs_model_r3_turn1]: nan\n",
      "[constr_freqs_model_r3_turn1]: nan\n",
      "[constrs_model_r4_turn1]: , you know ,|, you know|you know ,\n",
      "[constr_freqs_model_r4_turn1]: 4|4|4\n",
      "[constrs_human_turn2]: nan\n",
      "[constr_freqs_human_turn2]: nan\n",
      "[constrs_model_r0_turn2]: , you know ,.|but , you know|, you know|that's\n",
      "[constr_freqs_model_r0_turn2]: 2|2|4|2\n",
      "[constrs_model_r1_turn2]: nan\n",
      "[constr_freqs_model_r1_turn2]: nan\n",
      "[constrs_model_r2_turn2]: nan\n",
      "[constr_freqs_model_r2_turn2]: nan\n",
      "[constrs_model_r3_turn2]: that's ,\n",
      "[constr_freqs_model_r3_turn2]: 2.0\n",
      "[constrs_model_r4_turn2]: , you know ,|, you know|you know ,\n",
      "[constr_freqs_model_r4_turn2]: 4|4|4\n",
      "[constrs_human_turn3]: nan\n",
      "[constr_freqs_human_turn3]: nan\n",
      "[constrs_model_r0_turn3]: nan\n",
      "[constr_freqs_model_r0_turn3]: nan\n",
      "[constrs_model_r1_turn3]: nan\n",
      "[constr_freqs_model_r1_turn3]: nan\n",
      "[constrs_model_r2_turn3]: nan\n",
      "[constr_freqs_model_r2_turn3]: nan\n",
      "[constrs_model_r3_turn3]: nan\n",
      "[constr_freqs_model_r3_turn3]: nan\n",
      "[constrs_model_r4_turn3]: nan\n",
      "[constr_freqs_model_r4_turn3]: nan\n",
      "[constrs_human_turn4]: nan\n",
      "[constr_freqs_human_turn4]: nan\n",
      "[constrs_model_r0_turn4]: nan\n",
      "[constr_freqs_model_r0_turn4]: nan\n",
      "[constrs_model_r1_turn4]: nan\n",
      "[constr_freqs_model_r1_turn4]: nan\n",
      "[constrs_model_r2_turn4]: nan\n",
      "[constr_freqs_model_r2_turn4]: nan\n",
      "[constrs_model_r3_turn4]: nan\n",
      "[constr_freqs_model_r3_turn4]: nan\n",
      "[constrs_model_r4_turn4]: nan\n",
      "[constr_freqs_model_r4_turn4]: nan\n",
      "[constrs_human_turn5]: nan\n",
      "[constr_freqs_human_turn5]: nan\n",
      "[constrs_model_r0_turn5]: nan\n",
      "[constr_freqs_model_r0_turn5]: nan\n",
      "[constrs_model_r1_turn5]: nan\n",
      "[constr_freqs_model_r1_turn5]: nan\n",
      "[constrs_model_r2_turn5]: nan\n",
      "[constr_freqs_model_r2_turn5]: nan\n",
      "[constrs_model_r3_turn5]: nan\n",
      "[constr_freqs_model_r3_turn5]: nan\n",
      "[constrs_model_r4_turn5]: nan\n",
      "[constr_freqs_model_r4_turn5]: nan\n",
      "[constrs_human_turn6]: nan\n",
      "[constr_freqs_human_turn6]: nan\n",
      "[constrs_model_r0_turn6]: a pet .|a dog\n",
      "[constr_freqs_model_r0_turn6]: 2|2\n",
      "[constrs_model_r1_turn6]: nan\n",
      "[constr_freqs_model_r1_turn6]: nan\n",
      "[constrs_model_r2_turn6]: nan\n",
      "[constr_freqs_model_r2_turn6]: nan\n",
      "[constrs_model_r3_turn6]: nan\n",
      "[constr_freqs_model_r3_turn6]: nan\n",
      "[constrs_model_r4_turn6]: nan\n",
      "[constr_freqs_model_r4_turn6]: nan\n",
      "[constrs_human_turn7]: nan\n",
      "[constr_freqs_human_turn7]: nan\n",
      "[constrs_model_r0_turn7]: nan\n",
      "[constr_freqs_model_r0_turn7]: nan\n",
      "[constrs_model_r1_turn7]: nan\n",
      "[constr_freqs_model_r1_turn7]: nan\n",
      "[constrs_model_r2_turn7]: nan\n",
      "[constr_freqs_model_r2_turn7]: nan\n",
      "[constrs_model_r3_turn7]: nan\n",
      "[constr_freqs_model_r3_turn7]: nan\n",
      "[constrs_model_r4_turn7]: nan\n",
      "[constr_freqs_model_r4_turn7]: nan\n",
      "[constrs_human_turn8]: nan\n",
      "[constr_freqs_human_turn8]: nan\n",
      "[constrs_model_r0_turn8]: , you know\n",
      "[constr_freqs_model_r0_turn8]: 4.0\n",
      "[constrs_model_r1_turn8]: nan\n",
      "[constr_freqs_model_r1_turn8]: nan\n",
      "[constrs_model_r2_turn8]: nan\n",
      "[constr_freqs_model_r2_turn8]: nan\n",
      "[constrs_model_r3_turn8]: it would\n",
      "[constr_freqs_model_r3_turn8]: 2.0\n",
      "[constrs_model_r4_turn8]: , you know ,|, you know|you know ,|it would\n",
      "[constr_freqs_model_r4_turn8]: 4|4|4|2\n",
      "[ppl_human_response_gpt2]: 4.97797441482544\n",
      "[ppl_human_response_context_gpt2]: 2.86291241645813\n",
      "[ppl_model_response_r0_gpt2]: 3.8389151096344\n",
      "[ppl_model_response_r1_gpt2]: 4.007658958435059\n",
      "[ppl_model_response_r2_gpt2]: 7.181299209594727\n",
      "[ppl_model_response_r3_gpt2]: 4.3915324211120605\n",
      "[ppl_model_response_r4_gpt2]: 3.190514326095581\n",
      "[ppl_model_response_r0_context_gpt2]: 2.8333778381347656\n",
      "[ppl_model_response_r1_context_gpt2]: 2.8692197799682617\n",
      "[ppl_model_response_r2_context_gpt2]: 2.897299289703369\n",
      "[ppl_model_response_r3_context_gpt2]: 2.84946084022522\n",
      "[ppl_model_response_r4_context_gpt2]: 2.741380453109741\n",
      "[vo_human]: 0.5|0.5|0.5|0.5|0.5|0.5|0.5|0.5|0.5\n",
      "[co_human]: 0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0\n",
      "[vo_r0]: 0.45454545454545453|0.3181818181818182|0.45454545454545453|0...\n",
      "[co_r0]: 0.43478260869565216|0.13043478260869565|0.43478260869565216|...\n",
      "[vo_r1]: 0.4166666666666667|0.4166666666666667|0.4166666666666667|0.0...\n",
      "[co_r1]: 0.2222222222222222|0.2222222222222222|0.1111111111111111|0.0...\n",
      "[vo_r2]: 0.5|0.5|0.5|1.0|0.5|1.0|0.5|1.0|0.5\n",
      "[co_r2]: 0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0|0.0\n",
      "[vo_r3]: 0.4|0.3|0.43333333333333335|0.03333333333333333|0.3|0.033333...\n",
      "[co_r3]: 0.3055555555555556|0.05555555555555555|0.2777777777777778|0....\n",
      "[vo_r4]: 0.2972972972972973|0.1891891891891892|0.24324324324324326|0....\n",
      "[co_r4]: 0.3|0.06|0.12|0.0|0.06|0.0|0.26|0.24|0.0\n",
      "[pmi_human]: nan\n",
      "[pmi_human_constrs]: nan\n",
      "[pmi_r0]: 1.4515633753039578|3.321928094887362|3.321928094887362|3.321...\n",
      "[pmi_r0_constrs]: you know|but you know|a pet|a dog|that s\n",
      "[pmi_r1]: nan\n",
      "[pmi_r1_constrs]: nan\n",
      "[pmi_r2]: nan\n",
      "[pmi_r2_constrs]: nan\n",
      "[pmi_r3]: 2.6844981742720706|2.9499593175004044\n",
      "[pmi_r3_constrs]: it would|that s\n",
      "[pmi_r4]: 1.954063715833141|1.8365012677171206\n",
      "[pmi_r4_constrs]: you know|it would\n",
      "[comprehend_attribs]: -1.0|-0.007493647746741772|0.029944447800517082|0.0067034689...\n",
      "[comprehend_attribs_tag]: -0.6700357794761658|-0.19226841628551483|0.18234869837760925...\n"
     ]
    }
   ],
   "source": [
    "df_path = '../../data/samples_mini_gpt2_genq_constr_ppl_ol_pmi.tsv'\n",
    "\n",
    "# read the dataframe\n",
    "df = pd.read_csv(df_path, sep='\\t', header=0, index_col='sample_index')\n",
    "print('Rows: %d' % len(df))\n",
    "print('Columns: %d' % len(df.columns))\n",
    "print('Index: %s' % df.index.name)\n",
    "\n",
    "# print columns\n",
    "print('\\nCOLUMNS:')\n",
    "columns = df.columns\n",
    "for column in columns:\n",
    "    example_value = df[column].iloc[0]\n",
    "    try:\n",
    "        if len(example_value) > 60:\n",
    "            example_value = example_value[:60] + '...'\n",
    "    except:\n",
    "        pass\n",
    "    print(f'[{column}]: {example_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EXCERPT [670] FROM [SWITCHBOARD] CORPUS ---\n",
      "\u001b[93m[1]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mHuh. Well the, the, uh, clubs that we've got around here are\n",
      "         kind of expensive. but, uh, it's well worth it.. You can go\n",
      "         down and shoot up against a sand bag and some targets and h\n",
      "        ave, uh, competition.. Uh, I've never really joined a club b\n",
      "        ecause I haven't got the time. Not because I haven't got the\n",
      "         desire.. Uh, there's an annual membership fee, uh, that's, \n",
      "        that's fairly high.. Plus there's an initiation fee that you\n",
      "         have to pay because of first time, uh, uh, member.. So the \n",
      "        whole process can cost you a hundred fifty dollars to join t\n",
      "        he club.. Plus you have to pay for the, the ammunition in an\n",
      "        y tournaments that you would join in.\u001b[0m\n",
      "\u001b[93m[2]  \u001b[0m\u001b[96mB:\u001b[0m \u001b[96mYeah.. Well, that's what my husband,. when he was in that gu\n",
      "        n club where he was doing that tell if it's a cough or somet\n",
      "        hing was. It, you know,. he went mostly just to, uh, shoot a\n",
      "        t paper targets.\u001b[0m\n",
      "\u001b[93m[3]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mUh-huh.\u001b[0m\n",
      "\u001b[93m[4]  \u001b[0m\u001b[96mB:\u001b[0m \u001b[96mUh, but, you know, they used speed and accuracy and all that\n",
      "        .\u001b[0m\n",
      "\u001b[93m[5]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mI think that, that the gun clubs serve a useful purpose.. In\n",
      "         fact, I'd like to see somehow they tie the legislation into\n",
      "         not only when you buy a weapon you have to, uh, show that y\n",
      "        ou've gone to school or gone to some class to know how to ha\n",
      "        ndle that weapon.\u001b[0m\n",
      "\u001b[93m[6]  \u001b[0m\u001b[96mB:\u001b[0m \u001b[96mThat's a good,. I've never thought of that.. That's a good p\n",
      "        oint.\u001b[0m\n",
      "\u001b[93m[7]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mAnd, you know, it, it,. even after you wait your nine days, \n",
      "        if you don't know how to handle it, it's just like putting s\n",
      "        omeone in an automobile that doesn't know how to drive.. And\n",
      "         you give him a license because he waited nine days.\u001b[0m\n",
      "\u001b[93m[8]  \u001b[0m\u001b[96mB:\u001b[0m \u001b[96mYeah.. That's,. and, yeah.\u001b[0m\n",
      "\u001b[93m[9]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mHe could, he could not only, uh, uh, shoot himself.. He coul\n",
      "        d, he could, uh, mishandle a weapon. Leave it at home and le\n",
      "        t a child get at it.\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[92m[HUMAN]\u001b[0m\n",
      "     \u001b[96mB:\u001b[0m \u001b[96mIt,. well we, uh, we was living on a navy base down in Mem\n",
      "        phis. and, uh, this one guy decided to play, uh, lonesome co\n",
      "        wboy or something.. And he was twirling his gun around and s\n",
      "        hot himself in his foot.\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 1]\u001b[0m\n",
      "     \u001b[96mB: Yeah..\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 2]\u001b[0m\n",
      "     \u001b[96mB: Yeah, but, you know.. and, you know, it's not, it's not a\n",
      "         good thing to, you know, for parents to, you know..\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 3]\u001b[0m\n",
      "     \u001b[96mB: And, uh, it's okay.\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 4]\u001b[0m\n",
      "     \u001b[96mB: It's all so good.. That was good. So, I think. So, I like\n",
      "         to get to know some members at, the club.\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 5]\u001b[0m\n",
      "     \u001b[96mB: I saw a girl from Ohio that was in a room where she wasn'\n",
      "        t allowed..\u001b[0m\n",
      "\n",
      "--- EXCERPT [557] FROM [SWITCHBOARD] CORPUS ---\n",
      "\u001b[93m[1]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mI'm not counting on it.\u001b[0m\n",
      "\u001b[93m[2]  \u001b[0m\u001b[96mB:\u001b[0m \u001b[96mNo,. you don't count on Social Security.\u001b[0m\n",
      "\u001b[93m[3]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mYeah.\u001b[0m\n",
      "\u001b[93m[4]  \u001b[0m\u001b[96mB:\u001b[0m \u001b[96mBut, it's, it's,. that's what I'm saying,. they need to do s\n",
      "        omething else.\u001b[0m\n",
      "\u001b[93m[5]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mUm.\u001b[0m\n",
      "\u001b[93m[6]  \u001b[0m\u001b[96mB:\u001b[0m \u001b[96mBut.. Crime is going to go up as long as the economy stays d\n",
      "        own.\u001b[0m\n",
      "\u001b[93m[7]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mYeah.\u001b[0m\n",
      "\u001b[93m[8]  \u001b[0m\u001b[96mB:\u001b[0m \u001b[96mAnd it's going to get worse.\u001b[0m\n",
      "\u001b[93m[9]  \u001b[0m\u001b[95mA:\u001b[0m \u001b[95mYeah.\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[92m[HUMAN]\u001b[0m\n",
      "     \u001b[96mB:\u001b[0m \u001b[96mThat's just like last night they killed them people in tha\n",
      "        t store.. Where you at?\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 1]\u001b[0m\n",
      "     \u001b[96mB: And you're going to have to, you haven't talked about, yo\n",
      "        u have not talked about--\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 2]\u001b[0m\n",
      "     \u001b[96mB: And when you start spending money, the problem gets worse\n",
      "        . That's also how you see it.\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 3]\u001b[0m\n",
      "     \u001b[96mB: I'm seeing something of an impact on crime rate.\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 4]\u001b[0m\n",
      "     \u001b[96mB: Well, if you look at, you know,. if unemployment goes up,\n",
      "         and if it goes down, then it'll make more money for the eco\n",
      "        nomy.\u001b[0m\n",
      "\u001b[93m[10] \u001b[0m\u001b[91m[GPT2 - SAMPLE 5]\u001b[0m\n",
      "     \u001b[96mB: But..\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = 'switchboard'\n",
    "model_name = 'gpt2'\n",
    "n_samples = 2\n",
    "\n",
    "df_corpus = df[df['corpus'] == corpus]\n",
    "df_samples = df_corpus.sample(n_samples)\n",
    "\n",
    "for row_idx, row in df_samples.iterrows():\n",
    "    if row['corpus'] == corpus:\n",
    "        pretty_print_prompt(row, model_name, max_chars=60)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
